{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 160, 90\n",
    "\n",
    "train_data_dir = 'https://github.com/mateng0915/Food101DataSet/tree/master/Train'\n",
    "validation_data_dir = 'https://github.com/mateng0915/Food101DataSet/tree/master/Test'\n",
    "nb_train_samples = 625\n",
    "nb_validation_samples = 195\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(11))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "               metrics=[metrics.mae, metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 625 images belonging to 11 classes.\n",
      "Found 195 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "39/39 [==============================] - 119s 3s/step - loss: 2.3598 - mean_absolute_error: 0.4787 - categorical_accuracy: 0.1828 - val_loss: 2.2810 - val_mean_absolute_error: 0.4597 - val_categorical_accuracy: 0.1823\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 2.3033 - mean_absolute_error: 0.4485 - categorical_accuracy: 0.2101 - val_loss: 2.1222 - val_mean_absolute_error: 0.4175 - val_categorical_accuracy: 0.1979\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 99s 3s/step - loss: 2.0337 - mean_absolute_error: 0.3721 - categorical_accuracy: 0.2928 - val_loss: 1.8687 - val_mean_absolute_error: 0.3521 - val_categorical_accuracy: 0.2188\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 99s 3s/step - loss: 1.9637 - mean_absolute_error: 0.3375 - categorical_accuracy: 0.3015 - val_loss: 1.5637 - val_mean_absolute_error: 0.2612 - val_categorical_accuracy: 0.4271\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 1.8564 - mean_absolute_error: 0.2995 - categorical_accuracy: 0.3798 - val_loss: 1.5139 - val_mean_absolute_error: 0.2672 - val_categorical_accuracy: 0.4948\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 1.7404 - mean_absolute_error: 0.2662 - categorical_accuracy: 0.3723 - val_loss: 1.4029 - val_mean_absolute_error: 0.2264 - val_categorical_accuracy: 0.4740\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 1.5976 - mean_absolute_error: 0.2469 - categorical_accuracy: 0.4073 - val_loss: 1.3496 - val_mean_absolute_error: 0.2265 - val_categorical_accuracy: 0.5260\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 1.4808 - mean_absolute_error: 0.2098 - categorical_accuracy: 0.4692 - val_loss: 1.1436 - val_mean_absolute_error: 0.1651 - val_categorical_accuracy: 0.5938\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 1.4491 - mean_absolute_error: 0.2092 - categorical_accuracy: 0.4307 - val_loss: 1.1206 - val_mean_absolute_error: 0.1512 - val_categorical_accuracy: 0.4792\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 1.3424 - mean_absolute_error: 0.1787 - categorical_accuracy: 0.4885 - val_loss: 1.0747 - val_mean_absolute_error: 0.1580 - val_categorical_accuracy: 0.6979\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 1.3232 - mean_absolute_error: 0.1725 - categorical_accuracy: 0.5385 - val_loss: 1.0917 - val_mean_absolute_error: 0.1463 - val_categorical_accuracy: 0.6615\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 1.3466 - mean_absolute_error: 0.1542 - categorical_accuracy: 0.5513 - val_loss: 1.0949 - val_mean_absolute_error: 0.1199 - val_categorical_accuracy: 0.6042\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 1.1744 - mean_absolute_error: 0.1401 - categorical_accuracy: 0.5863 - val_loss: 0.7528 - val_mean_absolute_error: 0.0998 - val_categorical_accuracy: 0.7135\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 1.2378 - mean_absolute_error: 0.1451 - categorical_accuracy: 0.5404 - val_loss: 0.9059 - val_mean_absolute_error: 0.1168 - val_categorical_accuracy: 0.7188\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 1.0607 - mean_absolute_error: 0.1215 - categorical_accuracy: 0.6362 - val_loss: 0.8929 - val_mean_absolute_error: 0.1140 - val_categorical_accuracy: 0.6875\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 95s 2s/step - loss: 1.0107 - mean_absolute_error: 0.1137 - categorical_accuracy: 0.6390 - val_loss: 0.6509 - val_mean_absolute_error: 0.0903 - val_categorical_accuracy: 0.8125\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 99s 3s/step - loss: 1.0173 - mean_absolute_error: 0.1127 - categorical_accuracy: 0.6266 - val_loss: 0.6440 - val_mean_absolute_error: 0.0806 - val_categorical_accuracy: 0.8281\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 1.0062 - mean_absolute_error: 0.1087 - categorical_accuracy: 0.6584 - val_loss: 0.6023 - val_mean_absolute_error: 0.0765 - val_categorical_accuracy: 0.8073\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.9869 - mean_absolute_error: 0.0989 - categorical_accuracy: 0.6579 - val_loss: 0.4435 - val_mean_absolute_error: 0.0559 - val_categorical_accuracy: 0.8958\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.8632 - mean_absolute_error: 0.0922 - categorical_accuracy: 0.7035 - val_loss: 0.8878 - val_mean_absolute_error: 0.1175 - val_categorical_accuracy: 0.7344\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 0.9565 - mean_absolute_error: 0.0999 - categorical_accuracy: 0.6735 - val_loss: 0.4919 - val_mean_absolute_error: 0.0653 - val_categorical_accuracy: 0.8802\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 0.9165 - mean_absolute_error: 0.0933 - categorical_accuracy: 0.7086 - val_loss: 0.5132 - val_mean_absolute_error: 0.0668 - val_categorical_accuracy: 0.8698\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 0.9552 - mean_absolute_error: 0.0964 - categorical_accuracy: 0.6526 - val_loss: 0.5635 - val_mean_absolute_error: 0.0745 - val_categorical_accuracy: 0.8438\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 0.7068 - mean_absolute_error: 0.0791 - categorical_accuracy: 0.7611 - val_loss: 0.3789 - val_mean_absolute_error: 0.0530 - val_categorical_accuracy: 0.8854\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.7487 - mean_absolute_error: 0.0794 - categorical_accuracy: 0.7420 - val_loss: 0.4448 - val_mean_absolute_error: 0.0601 - val_categorical_accuracy: 0.8229\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.7508 - mean_absolute_error: 0.0814 - categorical_accuracy: 0.7136 - val_loss: 0.4934 - val_mean_absolute_error: 0.0616 - val_categorical_accuracy: 0.8646\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.7343 - mean_absolute_error: 0.0781 - categorical_accuracy: 0.7547 - val_loss: 1.1893 - val_mean_absolute_error: 0.0813 - val_categorical_accuracy: 0.6250\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 99s 3s/step - loss: 0.7128 - mean_absolute_error: 0.0760 - categorical_accuracy: 0.7514 - val_loss: 0.3997 - val_mean_absolute_error: 0.0576 - val_categorical_accuracy: 0.8958\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 0.6555 - mean_absolute_error: 0.0778 - categorical_accuracy: 0.7744 - val_loss: 0.3166 - val_mean_absolute_error: 0.0535 - val_categorical_accuracy: 0.9062\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 0.6869 - mean_absolute_error: 0.0767 - categorical_accuracy: 0.7440 - val_loss: 2.4934 - val_mean_absolute_error: 0.0878 - val_categorical_accuracy: 0.4062\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.7334 - mean_absolute_error: 0.0774 - categorical_accuracy: 0.7372 - val_loss: 0.3158 - val_mean_absolute_error: 0.0570 - val_categorical_accuracy: 0.8698\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 0.6730 - mean_absolute_error: 0.0748 - categorical_accuracy: 0.7707 - val_loss: 0.3139 - val_mean_absolute_error: 0.0546 - val_categorical_accuracy: 0.9271\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 0.5942 - mean_absolute_error: 0.0707 - categorical_accuracy: 0.7963 - val_loss: 0.2798 - val_mean_absolute_error: 0.0534 - val_categorical_accuracy: 0.9115\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 0.6503 - mean_absolute_error: 0.0741 - categorical_accuracy: 0.7851 - val_loss: 0.5837 - val_mean_absolute_error: 0.0774 - val_categorical_accuracy: 0.8177\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 0.6170 - mean_absolute_error: 0.0736 - categorical_accuracy: 0.7755 - val_loss: 0.2746 - val_mean_absolute_error: 0.0670 - val_categorical_accuracy: 0.8958\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 0.4962 - mean_absolute_error: 0.0698 - categorical_accuracy: 0.8461 - val_loss: 0.2412 - val_mean_absolute_error: 0.0625 - val_categorical_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "39/39 [==============================] - 97s 2s/step - loss: 0.6036 - mean_absolute_error: 0.0736 - categorical_accuracy: 0.7771 - val_loss: 0.2712 - val_mean_absolute_error: 0.0534 - val_categorical_accuracy: 0.9271\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.4811 - mean_absolute_error: 0.0705 - categorical_accuracy: 0.8124 - val_loss: 0.3007 - val_mean_absolute_error: 0.0526 - val_categorical_accuracy: 0.9375\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 0.5460 - mean_absolute_error: 0.0725 - categorical_accuracy: 0.8044 - val_loss: 0.2132 - val_mean_absolute_error: 0.0528 - val_categorical_accuracy: 0.9271\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.5215 - mean_absolute_error: 0.0709 - categorical_accuracy: 0.8188 - val_loss: 0.2055 - val_mean_absolute_error: 0.0558 - val_categorical_accuracy: 0.9427\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.4885 - mean_absolute_error: 0.0723 - categorical_accuracy: 0.8332 - val_loss: 0.3601 - val_mean_absolute_error: 0.0646 - val_categorical_accuracy: 0.8698\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 99s 3s/step - loss: 0.5311 - mean_absolute_error: 0.0712 - categorical_accuracy: 0.8077 - val_loss: 0.1759 - val_mean_absolute_error: 0.0505 - val_categorical_accuracy: 0.9167\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.5084 - mean_absolute_error: 0.0711 - categorical_accuracy: 0.8316 - val_loss: 0.1549 - val_mean_absolute_error: 0.0565 - val_categorical_accuracy: 0.9688\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 99s 3s/step - loss: 0.4674 - mean_absolute_error: 0.0711 - categorical_accuracy: 0.8220 - val_loss: 0.2640 - val_mean_absolute_error: 0.0612 - val_categorical_accuracy: 0.9167\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 0.4870 - mean_absolute_error: 0.0702 - categorical_accuracy: 0.8347 - val_loss: 0.4788 - val_mean_absolute_error: 0.0702 - val_categorical_accuracy: 0.8542\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 96s 2s/step - loss: 0.4677 - mean_absolute_error: 0.0715 - categorical_accuracy: 0.8477 - val_loss: 0.3952 - val_mean_absolute_error: 0.0707 - val_categorical_accuracy: 0.8698\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 100s 3s/step - loss: 0.5303 - mean_absolute_error: 0.0770 - categorical_accuracy: 0.8012 - val_loss: 0.3093 - val_mean_absolute_error: 0.0684 - val_categorical_accuracy: 0.8594\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.4253 - mean_absolute_error: 0.0749 - categorical_accuracy: 0.8525 - val_loss: 0.3354 - val_mean_absolute_error: 0.0759 - val_categorical_accuracy: 0.9115\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 98s 3s/step - loss: 0.4929 - mean_absolute_error: 0.0764 - categorical_accuracy: 0.8333 - val_loss: 0.1777 - val_mean_absolute_error: 0.0693 - val_categorical_accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 102s 3s/step - loss: 0.4465 - mean_absolute_error: 0.0762 - categorical_accuracy: 0.8445 - val_loss: 0.3640 - val_mean_absolute_error: 0.0721 - val_categorical_accuracy: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b803fac50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=int (nb_train_samples /batch_size),\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=int (nb_validation_samples / batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('Second_try.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
